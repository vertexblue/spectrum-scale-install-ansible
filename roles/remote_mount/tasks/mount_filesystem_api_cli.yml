---
#
# Get some cluster information
#
- name: Storage Cluster (owner) | GET the Cluster Information
  uri:
    validate_certs: no
    force_basic_auth: yes
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ scalemgmt_endpoint }}/cluster
    method: GET
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
    body_format: json
    status_code:
      - 200
  register: owning_cluster_info

- name: scale_remotemount_debug | Storage Cluster  (owner) | Print the Cluster Information
  debug:
    msg: "{{ owning_cluster_info }}"
  when: scale_remotemount_debug | bool

- name: Client Cluster (access) | GET the Cluster Information
  shell: /usr/lpp/mmfs/bin/mmlscluster -Y | grep -v HEADER | grep clusterSummary | cut -d ':' -f 9
  register: access_cluster_info
  changed_when: false
  failed_when: false

- name: scale_remotemount_debug | Client Cluster (access) | Print the Cluster Information
  debug:
    msg: "{{ access_cluster_info }}"
  when: scale_remotemount_debug | bool

- set_fact:
    access_cluster_name: "{{ access_cluster_info.stdout }}"
    owning_cluster_name: "{{ owning_cluster_info.json.cluster.clusterSummary.clusterName }}"

#
# When scale_remotemount_forceRun, do some cleanup to properly unmount and remove things
#
- name: Client Cluster (access) | Unmount the Remote FileSystem on all nodes.
  shell: "/usr/lpp/mmfs/bin/mmunmount {{ scale_remotemount_client_filesystem_name }} -a"
  register: access_cluster_unmount_fs
  run_once: True
  delegate_to: "{{ play_hosts | first }}"
  ignore_errors: true
  when: scale_remotemount_forceRun | bool

- name: Client Cluster (access) | Remove the Storage Cluster (Owning) from Access Cluster
  shell: "/usr/lpp/mmfs/bin/mmremotecluster delete {{ owning_cluster_name }}"
  register: access_cluster_unmount_fs
  run_once: True
  delegate_to: "{{ play_hosts | first }}"
  ignore_errors: true
  when: scale_remotemount_forceRun | bool

- name: Step 2
  debug:
    msg: "Exchange the keys between Storage and Client Clusters"

- name: "Storage Cluster (owner) | Check if the Client Cluster ('{{ access_cluster_name }}') is already defined"
  uri:
    validate_certs: no
    force_basic_auth: yes
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ remote_mount_endpoint }}/remoteclusters/{{ access_cluster_name }}
    method: GET
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
    body_format: json
    status_code:
      - 200
  register: remote_clusters_results
  ignore_errors: true

- name: Storage Cluster (owner) | Delete the Client Cluster, if it exists
  block:
    - name: "DELETE: {{ remote_mount_endpoint }}/remoteclusters/{{ access_cluster_name }}"
      uri:
        validate_certs: no
        force_basic_auth: true
        url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ remote_mount_endpoint }}/remoteclusters/{{ access_cluster_name }}
        method: DELETE
        user: "{{ scale_remotemount_storage_gui_username }}"
        password: "{{ scale_remotemount_storage_gui_password }}"
        status_code:
          - 202
      register: delete_call

    - name: "Checking results from the job: {{ delete_call.json.jobs[0].jobId }}"
      uri:
        validate_certs: no
        force_basic_auth: true
        url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ scalemgmt_endpoint }}/jobs/{{ delete_call.json.jobs[0].jobId }}
        method: GET
        user: "{{ scale_remotemount_storage_gui_username }}"
        password: "{{ scale_remotemount_storage_gui_password }}"
      register: completed_check
      until: completed_check.json.jobs[0].status == "COMPLETED"
      retries: "{{ restapi_retries_count }}"
      delay: "{{ restapi_retries_delay }}"
  when:
    - not remote_clusters_results.failed
    - scale_remotemount_forceRun | bool

- name: Client Cluster (Access) | Get the Public key from CLI
  shell: "cat /var/mmfs/ssl/id_rsa_committed.pub"
  register: accesskey_result

- name: scale_remotemount_debug | Print out the Client Cluster (access) Public Key results
  debug:
    msg: "{{ accesskey_result }}"
  when: scale_remotemount_debug | bool

- name: scale_remotemount_debug | Print out the Client Cluster (access) Public Key results to file /tmp/client_cluster.pub
  copy:
    dest: /tmp/client_cluster.pub
    content: "{{ accesskey_result }}\n"
  when: scale_remotemount_debug | bool

- name: Storage Cluster (owner) | Send the Public Key of the Client Cluster (access)
  uri:
    validate_certs: no
    force_basic_auth: true
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ remote_mount_endpoint }}/remoteclusters
    method: POST
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
    body_format: json
    body: |
      {
        "remoteCluster": "{{ access_cluster_name }}",
        "key": {{ accesskey_result.stdout_lines }}
      }
    status_code:
      - 202
  register: send_key

- name: "Storage Cluster (owner) | Check the result of adding the Client Cluster {{ send_key.json.jobs[0].jobId }}"
  uri:
    validate_certs: no
    force_basic_auth: true
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ scalemgmt_endpoint }}/jobs/{{ send_key.json.jobs[0].jobId }}
    method: GET
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
  register: completed_check
  until: completed_check.json.jobs[0].status != "FAILED"
  retries: "{{ restapi_retries_count }}"
  delay: "{{ restapi_retries_delay }}"

- name: Storage Cluster (owner) | Get the Public Key
  uri:
    validate_certs: no
    force_basic_auth: yes
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ remote_mount_endpoint }}/authenticationkey
    method: GET
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
    body_format: json
    status_code:
      - 200
  register: owningkey_result

  #TODO Change this to URI Module.
- name: Storage Cluster (owner) | Get the Public Key
  shell: "curl -k -u '{{ scale_remotemount_storage_gui_username }}':'{{ scale_remotemount_storage_gui_password }}' -X GET --header 'accept:application/json' 'https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ remote_mount_endpoint }}/authenticationkey'  | jq -r '.key[]' > {{ scale_remotemount_storage_pub_key_location }}"
  register: owningkey_result_curl

- name: scale_remotemount_debug | Print out the Storage Cluster (owning) Public Key results
  debug:
    msg: "{{ owningkey_result.json.key }}"
  when: scale_remotemount_debug | bool

- name: Step 3
  debug:
    msg: "Add the storage cluster (mmremotecluster add)"

- name: "Storage Cluster (owning) | GET Node Info - GET {{ scalemgmt_endpoint }}/nodes"
  uri:
    validate_certs: no
    force_basic_auth: yes
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ scalemgmt_endpoint }}/nodes
    method: GET
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
    body_format: json
    status_code:
      - 200
  register: owning_cluster_nodes

- set_fact:
    owning_nodes_name: []

- set_fact:
    owning_nodes_name: "{{ owning_nodes_name }} + [ '{{ item.adminNodeName }}' ]"
  with_items: "{{ owning_cluster_nodes.json.nodes }}"

- name: scale_remotemount_debug | Print out the array storing the nodes in the Storage Cluster (owning)
  debug:
    msg: "{{ owning_nodes_name }}"
  when: scale_remotemount_debug | bool

- name: Install storage cluster public key in remote cluster
  run_once: True
  delegate_to: "{{ play_hosts | first }}"
  shell: |
    /usr/lpp/mmfs/bin/mmremotecluster add {{ owning_cluster_name }} -n {{ owning_nodes_name | list | join(',') }} -k {{ scale_remotemount_storage_pub_key_location }}
  register: remote_cluster_add_ssh
  failed_when:
    - "remote_cluster_add_ssh.rc != 0 and 'is already defined' not in remote_cluster_add_ssh.stderr"
  tags:
    - remote_cluster

- name: Step 4
  debug:
    msg: "On Storage Cluster, add the access attributes for the Client Cluster"

- name: Storage Cluster (owning) | Set the client cluster access attributes on the Storage Cluster
  uri:
    validate_certs: no
    force_basic_auth: true
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ remote_mount_endpoint }}/remoteclusters/{{ access_cluster_name }}/access/{{ scale_remotemount_storage_filesystem_name }}
    method: POST
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
    body_format: json
    body: |
      {
        "access": "{{ scale_remotemount_access_mount_attributes }}"
      }
    status_code:
      - 202
  register: uri_result

- name: "Storage Cluster (owning) | Check the result of setting the access attributes on the Storage Cluster (JOB: {{ uri_result.json.jobs[0].jobId }})"
  uri:
    validate_certs: no
    force_basic_auth: true
    url: https://{{ scale_remotemount_storage_gui_hostname }}:{{ storage_cluster_gui_port }}/{{ scalemgmt_endpoint }}/jobs/{{ uri_result.json.jobs[0].jobId }}
    method: GET
    user: "{{ scale_remotemount_storage_gui_username }}"
    password: "{{ scale_remotemount_storage_gui_password }}"
  register: completed_check
  until: completed_check.json.jobs[0].status == "COMPLETED"
  retries: "{{ restapi_retries_count }}"
  delay: "{{ restapi_retries_delay }}"

- name: Step 5
  debug:
    msg: "Add the remotefileystem and mount it on the Client Side"

- name: Client Cluster (access) | Add remote filesystem
  run_once: True
  delegate_to: "{{ play_hosts | first }}"
  shell: |
    /usr/lpp/mmfs/bin/mmremotefs add {{ scale_remotemount_client_filesystem_name }} -f {{ scale_remotemount_storage_filesystem_name }} -C {{ owning_cluster_name }} -T {{ scale_remotemount_client_remotemount_path }} -o  {{ scale_remotemount_access_mount_attributes }}
  register: client_cluster_add_remotefs
  failed_when:
    - "client_cluster_add_remotefs.rc != 0 and 'There is already an existing file system using' not in client_cluster_add_remotefs.stderr"

- name: Client Cluster (access) | Mount remote filesystem on all client nodes
  run_once: True
  delegate_to: "{{ play_hosts | first }}"
  command: /usr/lpp/mmfs/bin/mmmount {{ scale_remotemount_client_filesystem_name }} -a
